
@misc{peyre_computational_2020,
	title = {Computational Optimal Transport},
	url = {http://arxiv.org/abs/1803.00567},
	abstract = {Optimal transport ({OT}) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in {OT} cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of {OT} in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, {OT} is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews {OT} with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of {OT} that make it particularly useful for some of these applications.},
	number = {{arXiv}:1803.00567},
	publisher = {{arXiv}},
	author = {Peyré, Gabriel and Cuturi, Marco},
	urldate = {2023-11-25},
	date = {2020-03-18},
	eprinttype = {arxiv},
	eprint = {1803.00567 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:files/869/1803.html:text/html;Full Text PDF:files/870/Peyré et Cuturi - 2020 - Computational Optimal Transport.pdf:application/pdf},
}

@article{peyre_course_nodate,
	title = {Course notes on Computational Optimal Transport},
	abstract = {These note cours are intended to complement the book [44] with more details on the theory of Optimal Transport. Many parts are extracted from this book, with some additions and re-writing.},
	author = {Peyre, Gabriel},
	langid = {english},
	file = {Peyre - Course notes on Computational Optimal Transport.pdf:files/871/Peyre - Course notes on Computational Optimal Transport.pdf:application/pdf},
}

@misc{claici_stochastic_2018,
	title = {Stochastic Wasserstein Barycenters},
	url = {http://arxiv.org/abs/1802.05757},
	abstract = {We present a stochastic algorithm to compute the barycenter of a set of probability distributions under the Wasserstein metric from optimal transport. Unlike previous approaches, our method extends to continuous input distributions and allows the support of the barycenter to be adjusted in each iteration. We tackle the problem without regularization, allowing us to recover a sharp output whose support is contained within the support of the true barycenter. We give examples where our algorithm recovers a more meaningful barycenter than previous work. Our method is versatile and can be extended to applications such as generating super samples from a given distribution and recovering blue noise approximations.},
	number = {{arXiv}:1802.05757},
	publisher = {{arXiv}},
	author = {Claici, Sebastian and Chien, Edward and Solomon, Justin},
	urldate = {2023-12-21},
	date = {2018-06-06},
	eprinttype = {arxiv},
	eprint = {1802.05757 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:files/1043/1802.html:text/html;Full Text PDF:files/1044/Claici et al. - 2018 - Stochastic Wasserstein Barycenters.pdf:application/pdf},
}

@article{flamary_pot_2021,
	title = {{POT}: Python Optimal Transport},
	volume = {22},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v22/20-451.html},
	shorttitle = {{POT}},
	abstract = {Optimal transport has recently been reintroduced to the machine learning community thanks in part to novel efficient optimization procedures allowing for medium to large scale applications. We propose a Python toolbox that implements several key optimal transport ideas for the machine learning community. The toolbox contains implementations of a number of founding works of {OT} for machine learning such as Sinkhorn algorithm and Wasserstein barycenters, but also provides generic solvers that can be used for conducting novel fundamental research. This toolbox, named {POT} for Python Optimal Transport, is open source with an {MIT} license.},
	pages = {1--8},
	number = {78},
	journaltitle = {Journal of Machine Learning Research},
	author = {Flamary, Rémi and Courty, Nicolas and Gramfort, Alexandre and Alaya, Mokhtar Z. and Boisbunon, Aurélie and Chambon, Stanislas and Chapel, Laetitia and Corenflos, Adrien and Fatras, Kilian and Fournier, Nemo and Gautheron, Léo and Gayraud, Nathalie T. H. and Janati, Hicham and Rakotomamonjy, Alain and Redko, Ievgen and Rolet, Antoine and Schutz, Antony and Seguy, Vivien and Sutherland, Danica J. and Tavenard, Romain and Tong, Alexander and Vayer, Titouan},
	urldate = {2024-01-13},
	date = {2021},
	file = {Full Text PDF:files/1187/Flamary et al. - 2021 - POT Python Optimal Transport.pdf:application/pdf;Source Code:files/1188/POT.html:text/html},
}

@misc{benamou_iterative_2014,
	title = {Iterative Bregman Projections for Regularized Transportation Problems},
	url = {http://arxiv.org/abs/1412.5154},
	abstract = {This article details a general numerical framework to approximate so-lutions to linear programs related to optimal transport. The general idea is to introduce an entropic regularization of the initial linear program. This regularized problem corresponds to a Kullback-Leibler Bregman di-vergence projection of a vector (representing some initial joint distribu-tion) on the polytope of constraints. We show that for many problems related to optimal transport, the set of linear constraints can be split in an intersection of a few simple constraints, for which the projections can be computed in closed form. This allows us to make use of iterative Bregman projections (when there are only equality constraints) or more generally Bregman-Dykstra iterations (when inequality constraints are in-volved). We illustrate the usefulness of this approach to several variational problems related to optimal transport: barycenters for the optimal trans-port metric, tomographic reconstruction, multi-marginal optimal trans-port and in particular its application to Brenier's relaxed solutions of in-compressible Euler equations, partial un-balanced optimal transport and optimal transport with capacity constraints.},
	number = {{arXiv}:1412.5154},
	publisher = {{arXiv}},
	author = {Benamou, Jean-David and Carlier, Guillaume and Cuturi, Marco and Nenna, Luca and Peyré, Gabriel},
	urldate = {2024-01-13},
	date = {2014-12-16},
	eprinttype = {arxiv},
	eprint = {1412.5154 [math]},
	keywords = {Mathematics - Analysis of {PDEs}, Mathematics - Numerical Analysis},
	file = {arXiv.org Snapshot:files/1190/1412.html:text/html;Full Text PDF:files/1191/Benamou et al. - 2014 - Iterative Bregman Projections for Regularized Tran.pdf:application/pdf},
}

@article{agueh_barycenters_2011,
	title = {Barycenters in the Wasserstein Space},
	volume = {43},
	issn = {0036-1410, 1095-7154},
	url = {http://epubs.siam.org/doi/10.1137/100805741},
	doi = {10.1137/100805741},
	abstract = {In this paper, we introduce a notion of barycenter in the Wasserstein space which generalizes {McCann}'s interpolation to the case of more than two measures. We provide existence, uniqueness, characterizations, and regularity of the barycenter and relate it to the multimarginal optimal transport problem considered by Gangbo and Świech in [Comm. Pure Appl. Math., 51 (1998), pp. 23–45]. We also consider some examples and, in particular, rigorously solve the Gaussian case. We finally discuss convexity of functionals in the Wasserstein space.},
	pages = {904--924},
	number = {2},
	journaltitle = {{SIAM} Journal on Mathematical Analysis},
	shortjournal = {{SIAM} J. Math. Anal.},
	author = {Agueh, Martial and Carlier, Guillaume},
	urldate = {2024-01-13},
	date = {2011-01},
	langid = {english},
	file = {Version soumise:files/1195/Agueh et Carlier - 2011 - Barycenters in the Wasserstein Space.pdf:application/pdf},
}

@incollection{bruckstein_wasserstein_2012,
	location = {Berlin, Heidelberg},
	title = {Wasserstein Barycenter and Its Application to Texture Mixing},
	volume = {6667},
	isbn = {978-3-642-24784-2 978-3-642-24785-9},
	url = {http://link.springer.com/10.1007/978-3-642-24785-9_37},
	abstract = {This paper proposes a new deﬁnition of the averaging of discrete probability distributions as a barycenter over the Wasserstein space. Replacing the Wasserstein original metric by a sliced approximation over 1D distributions allows us to use a fast stochastic gradient descent algorithm. This new notion of barycenter of probabilities is likely to ﬁnd applications in computer vision where one wants to average features deﬁned as distributions. We show an application to texture synthesis and mixing, where a texture is characterized by the distribution of the response to a multiscale oriented ﬁlter bank. This leads to a simple way to navigate over a convex domain of color textures.},
	pages = {435--446},
	booktitle = {Scale Space and Variational Methods in Computer Vision},
	publisher = {Springer Berlin Heidelberg},
	author = {Rabin, Julien and Peyré, Gabriel and Delon, Julie and Bernot, Marc},
	editor = {Bruckstein, Alfred M. and Ter Haar Romeny, Bart M. and Bronstein, Alexander M. and Bronstein, Michael M.},
	urldate = {2024-01-13},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-24785-9_37},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Rabin et al. - 2012 - Wasserstein Barycenter and Its Application to Text.pdf:files/1196/Rabin et al. - 2012 - Wasserstein Barycenter and Its Application to Text.pdf:application/pdf},
}

@inproceedings{cheng_dynamical_2021,
	title = {Dynamical Wasserstein Barycenters for Time-series Modeling},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/ebb71045453f38676c40deb9864f811d-Abstract.html},
	abstract = {Many time series can be modeled as a sequence of segments representing high-level discrete states, such as running and walking in a human activity application. Flexible models should describe the system state and observations in stationary ``pure-state'' periods as well as transition periods between adjacent segments, such as a gradual slowdown between running and walking. However, most prior work assumes instantaneous transitions between pure discrete states. We propose a dynamical Wasserstein barycentric ({DWB}) model that estimates the system state over time as well as the data-generating distributions of pure states in an unsupervised manner. Our model assumes each pure state generates data from a multivariate normal distribution, and characterizes transitions between states via displacement-interpolation specified by the Wasserstein barycenter. The system state is represented by a barycentric weight vector which evolves over time via a random walk on the simplex. Parameter learning leverages the natural Riemannian geometry of Gaussian distributions under the Wasserstein distance, which leads to improved convergence speeds. Experiments on several human activity datasets show that our proposed {DWB} model accurately learns the generating distribution of pure states while improving state estimation for transition periods compared to the commonly used linear interpolation mixture models.},
	pages = {27991--28003},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Cheng, Kevin and Aeron, Shuchin and Hughes, Michael C and Miller, Eric L},
	urldate = {2024-01-13},
	date = {2021},
	file = {Full Text PDF:files/1199/Cheng et al. - 2021 - Dynamical Wasserstein Barycenters for Time-series .pdf:application/pdf},
}

@misc{cheng_nonparametric_2023,
	title = {Nonparametric and Regularized Dynamical Wasserstein Barycenters for Sequential Observations},
	url = {http://arxiv.org/abs/2210.01918},
	doi = {10.1109/TSP.2023.330361},
	abstract = {We consider probabilistic models for sequential observations which exhibit gradual transitions among a finite number of states. We are particularly motivated by applications such as human activity analysis where observed accelerometer time series contains segments representing distinct activities, which we call pure states, as well as periods characterized by continuous transition among these pure states. To capture this transitory behavior, the dynamical Wasserstein barycenter ({DWB}) model of Cheng et al. in 2021 [1] associates with each pure state a data-generating distribution and models the continuous transitions among these states as a Wasserstein barycenter of these distributions with dynamically evolving weights. Focusing on the univariate case where Wasserstein distances and barycenters can be computed in closed form, we extend [1] specifically relaxing the parameterization of the pure states as Gaussian distributions. We highlight issues related to the uniqueness in identifying the model parameters as well as uncertainties induced when estimating a dynamically evolving distribution from a limited number of samples. To ameliorate non-uniqueness, we introduce regularization that imposes temporal smoothness on the dynamics of the barycentric weights. A quantile-based approximation of the pure state distributions yields a finite dimensional estimation problem which we numerically solve using cyclic descent alternating between updates to the pure-state quantile functions and the barycentric weights. We demonstrate the utility of the proposed algorithm in segmenting both simulated and real world human activity time series.},
	author = {Cheng, Kevin C. and Aeron, Shuchin and Hughes, Michael C. and Miller, Eric L.},
	urldate = {2024-01-13},
	date = {2023-09-21},
	eprinttype = {arxiv},
	eprint = {2210.01918 [cs, eess]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv.org Snapshot:files/1209/2210.html:text/html;Full Text PDF:files/1210/Cheng et al. - 2023 - Nonparametric and Regularized Dynamical Wasserstei.pdf:application/pdf},
}

@article{korotin_wasserstein_nodate,
	title = {Wasserstein Iterative Networks for Barycenter Estimation},
	abstract = {Wasserstein barycenters have become popular due to their ability to represent the average of probability measures in a geometrically meaningful way. In this paper, we present an algorithm to approximate the Wasserstein-2 barycenters of continuous measures via a generative model. Previous approaches rely on regularization (entropic/quadratic) which introduces bias or on input convex neural networks which are not expressive enough for large-scale tasks. In contrast, our algorithm does not introduce bias and allows using arbitrary neural networks. In addition, based on the celebrity faces dataset, we construct Ave, celeba! dataset which can be used for quantitative evaluation of barycenter algorithms by using standard metrics of generative models such as {FID}.},
	author = {Korotin, Alexander and Egiazarian, Vage and Li, Lingxiao and Burnaev, Evgeny},
	langid = {english},
	file = {Korotin et al. - Wasserstein Iterative Networks for Barycenter Esti.pdf:files/1211/Korotin et al. - Wasserstein Iterative Networks for Barycenter Esti.pdf:application/pdf},
}

@inproceedings{dvurechenskii_decentralize_2018,
	title = {Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/161882dd2d19c716819081aee2c08b98-Abstract.html},
	shorttitle = {Decentralize and Randomize},
	abstract = {We study the decentralized distributed computation of discrete approximations for the regularized Wasserstein barycenter of a finite set of continuous probability measures distributedly stored over a network. We assume there is a network of agents/machines/computers, and each agent holds a private continuous probability measure and seeks to compute the barycenter of all the measures in the network by getting samples from its local measure and exchanging information with its neighbors. Motivated by this problem, we develop, and analyze, a novel accelerated primal-dual stochastic gradient method for general stochastic convex optimization problems with linear equality constraints. Then, we apply this method to the decen- tralized distributed optimization setting to obtain a new algorithm for the distributed semi-discrete regularized Wasserstein barycenter problem. Moreover, we show explicit non-asymptotic complexity for the proposed algorithm. Finally, we show the effectiveness of our method on the distributed computation of the regularized Wasserstein barycenter of univariate Gaussian and von Mises distributions, as well as some applications to image aggregation.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Dvurechenskii, Pavel and Dvinskikh, Darina and Gasnikov, Alexander and Uribe, Cesar and Nedich, Angelia},
	urldate = {2024-01-13},
	date = {2018},
	file = {Full Text PDF:files/1214/Dvurechenskii et al. - 2018 - Decentralize and Randomize Faster Algorithm for W.pdf:application/pdf},
}

@misc{cuturi_sinkhorn_2013,
	title = {Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances},
	url = {http://arxiv.org/abs/1306.0895},
	doi = {10.48550/arXiv.1306.0895},
	shorttitle = {Sinkhorn Distances},
	abstract = {Optimal transportation distances are a fundamental family of parameterized distances for histograms. Despite their appealing theoretical properties, excellent performance in retrieval tasks and intuitive formulation, their computation involves the resolution of a linear program whose cost is prohibitive whenever the histograms' dimension exceeds a few hundreds. We propose in this work a new family of optimal transportation distances that look at transportation problems from a maximum-entropy perspective. We smooth the classical optimal transportation problem with an entropic regularization term, and show that the resulting optimum is also a distance which can be computed through Sinkhorn-Knopp's matrix scaling algorithm at a speed that is several orders of magnitude faster than that of transportation solvers. We also report improved performance over classical optimal transportation distances on the {MNIST} benchmark problem.},
	number = {{arXiv}:1306.0895},
	publisher = {{arXiv}},
	author = {Cuturi, Marco},
	urldate = {2024-01-13},
	date = {2013-06-04},
	eprinttype = {arxiv},
	eprint = {1306.0895 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:files/1230/Cuturi - 2013 - Sinkhorn Distances Lightspeed Computation of Opti.pdf:application/pdf;arXiv.org Snapshot:files/1231/1306.html:text/html},
}

@misc{staib_parallel_2017,
	title = {Parallel Streaming Wasserstein Barycenters},
	url = {http://arxiv.org/abs/1705.07443},
	abstract = {Eﬃciently aggregating data from diﬀerent sources is a challenging problem, particularly when samples from each source are distributed diﬀerently. These diﬀerences can be inherent to the inference task or present for other reasons: sensors in a sensor network may be placed far apart, aﬀecting their individual measurements. Conversely, it is computationally advantageous to split Bayesian inference tasks across subsets of data, but data need not be identically distributed across subsets. One principled way to fuse probability distributions is via the lens of optimal transport: the Wasserstein barycenter is a single distribution that summarizes a collection of input measures while respecting their geometry. However, computing the barycenter scales poorly and requires discretization of all input distributions and the barycenter itself. Improving on this situation, we present a scalable, communication-eﬃcient, parallel algorithm for computing the Wasserstein barycenter of arbitrary distributions. Our algorithm can operate directly on continuous input distributions and is optimized for streaming data. Our method is even robust to nonstationary input distributions and produces a barycenter estimate that tracks the input measures over time. The algorithm is semi-discrete, needing to discretize only the barycenter estimate. To the best of our knowledge, we also provide the ﬁrst bounds on the quality of the approximate barycenter as the discretization becomes ﬁner. Finally, we demonstrate the practical eﬀectiveness of our method, both in tracking moving distributions on a sphere, as well as in a large-scale Bayesian inference task.},
	number = {{arXiv}:1705.07443},
	publisher = {{arXiv}},
	author = {Staib, Matthew and Claici, Sebastian and Solomon, Justin and Jegelka, Stefanie},
	urldate = {2024-01-13},
	date = {2017-11-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1705.07443 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Statistics - Computation},
	file = {Staib et al. - 2017 - Parallel Streaming Wasserstein Barycenters.pdf:files/1242/Staib et al. - 2017 - Parallel Streaming Wasserstein Barycenters.pdf:application/pdf},
}

@article{nesterov_method_1983,
	title = {A method for solving the convex programming problem with convergence rate O(1/k{\textasciicircum}2)},
	url = {https://www.semanticscholar.org/paper/A-method-for-solving-the-convex-programming-problem-Nesterov/8d3a318b62d2e970122da35b2a2e70a5d12cc16f},
	abstract = {Semantic Scholar extracted view of "A method for solving the convex programming problem with convergence rate O(1/k{\textasciicircum}2)" by Y. Nesterov},
	journaltitle = {Proceedings of the {USSR} Academy of Sciences},
	author = {Nesterov, Y.},
	urldate = {2024-01-14},
	date = {1983},
}

@misc{cuturi_fast_2014,
	title = {Fast Computation of Wasserstein Barycenters},
	url = {http://arxiv.org/abs/1310.4375},
	abstract = {We present new algorithms to compute the mean of a set of empirical probability measures under the optimal transport metric. This mean, known as the Wasserstein barycenter, is the measure that minimizes the sum of its Wasserstein distances to each element in that set. We propose two original algorithms to compute Wasserstein barycenters that build upon the subgradient method. A direct implementation of these algorithms is, however, too costly because it would require the repeated resolution of large primal and dual optimal transport problems to compute subgradients. Extending the work of Cuturi (2013), we propose to smooth the Wasserstein distance used in the definition of Wasserstein barycenters with an entropic regularizer and recover in doing so a strictly convex objective whose gradients can be computed for a considerably cheaper computational cost using matrix scaling algorithms. We use these algorithms to visualize a large family of images and to solve a constrained clustering problem.},
	number = {{arXiv}:1310.4375},
	publisher = {{arXiv}},
	author = {Cuturi, Marco and Doucet, Arnaud},
	urldate = {2024-01-14},
	date = {2014-06-17},
	eprinttype = {arxiv},
	eprint = {1310.4375 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:files/1267/1310.html:text/html;Full Text PDF:files/1268/Cuturi et Doucet - 2014 - Fast Computation of Wasserstein Barycenters.pdf:application/pdf},
}

@article{mccann_convexity_1997,
	title = {A Convexity Principle for Interacting Gases},
	volume = {128},
	issn = {0001-8708},
	url = {https://www.sciencedirect.com/science/article/pii/S0001870897916340},
	doi = {10.1006/aima.1997.1634},
	abstract = {A new set of inequalities is introduced, based on a novel but natural interpolation between Borel probability measures {onRd}. Using these estimates in lieu of convexity or rearrangement inequalities, the existence and uniqueness problems are solved for a family of attracting gas models. In these models, the gas interacts with itself through a force which increases with distance and is governed by an equation of {stateP}=P(ϱ) relating pressure to density.P(ϱ)/ϱ{\textgreater}(d−1)/dis assumed non-decreasing for ad-dimensional gas. By showing that the internal and potential energies for the system are convex functions of the interpolation parameter, an energy minimizing state—unique up to translation—is proven to exist. The concavity established for ¶ρt¶−p/dqas a function oft∈[0,1] generalizes the Brunn–Minkowski inequality from sets to measures.},
	pages = {153--179},
	number = {1},
	journaltitle = {Advances in Mathematics},
	shortjournal = {Advances in Mathematics},
	author = {{McCann}, Robert J.},
	urldate = {2024-01-15},
	date = {1997-06-01},
	file = {ScienceDirect Snapshot:files/1273/S0001870897916340.html:text/html},
}
