
@misc{peyre_computational_2020,
	title = {Computational Optimal Transport},
	url = {http://arxiv.org/abs/1803.00567},
	abstract = {Optimal transport ({OT}) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in {OT} cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of {OT} in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, {OT} is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews {OT} with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of {OT} that make it particularly useful for some of these applications.},
	number = {{arXiv}:1803.00567},
	publisher = {{arXiv}},
	author = {Peyr√©, Gabriel and Cuturi, Marco},
	urldate = {2023-11-25},
	date = {2020-03-18},
	eprinttype = {arxiv},
	eprint = {1803.00567 [stat]},
	keywords = {Statistics - Machine Learning},
}

@article{peyre_course_nodate,
	title = {Course notes on Computational Optimal Transport},
	abstract = {These note cours are intended to complement the book [44] with more details on the theory of Optimal Transport. Many parts are extracted from this book, with some additions and re-writing.},
	author = {Peyre, Gabriel},
	langid = {english},
}

@misc{claici_stochastic_2018,
	title = {Stochastic Wasserstein Barycenters},
	url = {http://arxiv.org/abs/1802.05757},
	abstract = {We present a stochastic algorithm to compute the barycenter of a set of probability distributions under the Wasserstein metric from optimal transport. Unlike previous approaches, our method extends to continuous input distributions and allows the support of the barycenter to be adjusted in each iteration. We tackle the problem without regularization, allowing us to recover a sharp output whose support is contained within the support of the true barycenter. We give examples where our algorithm recovers a more meaningful barycenter than previous work. Our method is versatile and can be extended to applications such as generating super samples from a given distribution and recovering blue noise approximations.},
	number = {{arXiv}:1802.05757},
	publisher = {{arXiv}},
	author = {Claici, Sebastian and Chien, Edward and Solomon, Justin},
	urldate = {2023-11-21},
	date = {2018-06-06},
	eprinttype = {arxiv},
	eprint = {1802.05757 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}
